# ä¸­é—´ä»¶

```python
uid = f"{platform}:{user_id}"
```

## ğŸ”© åª’ä½“ç±»å‹è½¬æ¢å™¨

::: danger
æ­¤èŠ‚å†…å®¹é”™è¯¯
:::

ç”¨äºè½¬æ¢åª’ä½“ç±»å‹å’Œæ³¨å…¥æ–‡ä»¶å¯¹è±¡ã€‚ç”¨äº Ttsåœºæ™¯ï¼Œæ–‡æœ¬è½¬æ–‡ä»¶å‘é€åœºæ™¯ã€‚

```python
from typing import List

from llmkira.sdk.schema import File
from llmkira.transducer import resign_transfer, Builder, Parser

__receiver_name__ = "discord"


@resign_transfer(agent_name=__receiver_name__)
class Builder(Builder):
    def build(self, message, *args) -> (bool, List[File]):
        """
        åè½ receiver å¹³å°,ä»…ä»… hook LLM çš„æ­£å¸¸å›å¤ï¼Œå³ reply å‡½æ•°ã€‚
        :param message: å•æ¡é€šç”¨æ¶ˆæ¯ (RawMessage)
        :param args: å…¶ä»–å‚æ•°
        :return: æ˜¯å¦æ”¾å¼ƒå‘é€æ–‡æœ¬, éœ€è¦å‘é€çš„æ–‡ä»¶åˆ—è¡¨(RawMessage.upload)
        """
        return False, []


@resign_transfer(agent_name=__receiver_name__)
class Parser(Parser):
    def parse(self, message, file: List[File], *args) -> (list, List[File]):
        """
        æ¥æ”¶ sender å¹³å°çš„ **åŸå§‹** æ¶ˆæ¯ï¼Œè¿”å›æ–‡ä»¶ã€‚
        éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œçš„ message æ˜¯åŸå§‹æ¶ˆæ¯ï¼Œä¸æ˜¯æˆ‘ä»¬è½¬æ¢åçš„é€šç”¨æ¶ˆæ¯ç±»å‹ã€‚
        :param message: å•æ¡åŸå§‹æ¶ˆæ¯
        :param file: æ–‡ä»¶åˆ—è¡¨
        :param args: å…¶ä»–å‚æ•°
        :return: è¿”å› **è¿½åŠ çš„** æ¶ˆæ¯åˆ—è¡¨,è¿”å›æ–‡ä»¶åˆ—è¡¨, 
        """
        return [], file


````

- Builder çš„è¢«ä½¿ç”¨åœºæ™¯

```python
# è½¬æå™¨
_transfer = TransferManager().receiver_builder(agent_name=__receiver__)
just_file, file_list = _transfer().build(message=item)
```

- Parser çš„è¢«ä½¿ç”¨åœºæ™¯

```python
# è½¬æå™¨
_transfer = TransferManager().sender_parser(agent_name=__sender__)
deliver_back_message, _file = _transfer().parse(message=message, file=_file)
```

## ğŸŸ è®¡è´¹ç»„ä»¶

```python
from llmkira.middleware.user import SubManager, UserInfo


class EXP():
    """
    ç”¨æ³•ç¤ºä¾‹
    """

    @staticmethod
    async def llm_task(task, task_desc, raw_data):
        _submanager = SubManager(user_id=f"{task.sender.platform}:{task.sender.user_id}")
        driver = _submanager.llm_driver  # ç”±å‘é€äººæ‰¿æ‹…æ¥å—è€…çš„æˆæœ¬
        model_name = os.getenv("OPENAI_API_MODEL", "gpt-3.5-turbo-0613")
        endpoint = openai.Openai(
            config=driver,
            model=model_name,
            messages=Message.create_task_message_list(
                task_desc=task_desc,
                refer=raw_data
            ),
        )
        # è°ƒç”¨Openai
        result = await endpoint.create()
        await _submanager.add_cost(
            cost=UserInfo.Cost(token_usage=result.usage.total_tokens, token_uuid=driver.uuid, model_name=model_name)
        )
        return result.default_message.content

```

## ğŸ³ å®šæ—¶ä»»åŠ¡æ³¨å†Œ

```python
from llmkira.receiver.aps import SCHEDULER

SCHEDULER.add_job(
    func=_send,  # å¼‚æ­¥å‡½æ•°
    id=str(time.time()),
    trigger="date",
    replace_existing=True,
    run_date=datetime.datetime.now() + datetime.timedelta(minutes=_set.delay),
    args=[receiver, _set]  # å‚æ•°ä¼ é€’
)
# å¯åŠ¨
try:
    SCHEDULER.start()
except Exception as e:
    pass
```

## ğŸ¥ ENV

```python
_env_dict = await EnvManager.from_uid(uid=_task.receiver.uid).get_env_list(name_list=_tool_obj.env_required)
assert isinstance(_env_dict, dict), "env_dict must be dict"

```
