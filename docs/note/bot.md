## 笔记

> 以后如果chatGPT开放接口会尝试做兼容。

### 应用尝试

- 基于检索的记忆池设计

受限于模型的输入限制。在设计上，我采用基于上下文检索的记忆池作为增强手段，来实现 100 轮上下的检索技巧。

其中主要应用的是余弦相似度计算和主题匹配。

- 聊天的角色增强

让每个使用者可以自由定制，聊天框架通用且与 GPT3 Api 深度结合。

- 安全性的增强

接入了 Openai 的官方审核端点和DFA审查。改进了审查，无视了字符隔离，和支持简繁通杀。

- 实时检索插件系统

在 kira 包中，实现了一套实时支持系统，为用户提供即时的互联网信息。
逻辑即 检查文本条件后注入相应的文本。
但是这会导致错误。

- 语音结合的尝试

基于VITS项目，做到了语言识别并转语音输出的效果。

### 信息层次

`x>80` 忘记
`4<x<80` 中间记忆
`x<4` 强记忆

### Some refer

*InstructGPT 论文*

https://arxiv.org/pdf/2203.02155.pdf
https://www.bilibili.com/video/BV1hd4y187CR

*解释ChatGpt*

https://www.assemblyai.com/blog/how-chatgpt-actually-works/

### Info

ChatGPT 基于原始的 GPT-3 模型，但经过进一步训练，使用人工反馈来指导学习过程，具体目标是减轻模型的错位问题。

所使用的具体技术，称为从人类反馈中强化学习，是基于 先前的学术研究 。 ChatGPT 代表了 第一个将这种技术用于生产模型的案例。

根据 OpenAI 的说法，ChatGPT 已经 “使用与 InstructGPT 相同的方法进行训练，但数据收集设置略有不同”，ChatGPT 的论文尚未公开。

*Codex*

Codex 的中文效果不怎么好...

*原始 GPT3*

缺乏帮助：不遵循用户的明确指示。

幻觉：模型编造了不存在的或错误的事实。

缺乏可解释性：人类很难理解模型是如何做出特定决定或预测的。

生成有偏见或有毒的输出：在有偏见/有毒数据上训练的语言模型可能会在其输出中重现该结果，即使没有明确指示这样做。 

### ChatGPT 的安全调整

ChatGPT 在公测中不断完善其漏洞，便于以后的商业化推进。每个用户的对话记录会用于 需求分析 和 安全调整 中。

## 复刻结论

基于注入和检索强化的 GPT3 不能和 ChatGPT 竞争。

